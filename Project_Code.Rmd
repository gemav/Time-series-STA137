---
title: "Project"
author: "Gema Vidal_7526, Tadaishi Yatabe-Rodriguez_ID_997887941"
date: "March 6, 2017"
output: word_document
---

Loading packages
```{r}
library("astsa")
library("forecast")
library("nlme")
```


Setting working directory
```{r, eval = FALSE}
# from Gema's PC
setwd("/Users/gvidal/Box Sync/Vet/MPVM & PhD/PhD 2016_2017 Winter Quarter (gvidal@ucdavis.edu)/STA 137/Project")

# from Gema's Mac
setwd("/Users/gemavidal/Box Sync/Vet/MPVM & PhD/PhD 2016_2017 Winter Quarter (gvidal@ucdavis.edu)/STA 137/Project")

# from Tada's PC
setwd("C:/Users/tyatabe/OneDrive/Docs/PhD Epi/Winter_17/Time series/Project2/Trial")
# From Tada's laptop
setwd("C:/Users/Tadaishi/SkyDrive//Docs/PhD Epi/Winter_17/Time series/Project2/Trial")

df <- read.table("bostonArmedRobberies.txt", header = FALSE)
head(df)
dim(df)
colnames(df) <- c("month", "crimes")
```




1. Use graphical techniques to inspect the data. Describe the behaviour of the data. Mention any features you think may be important for analysis and forecasting.
```{r}
par(mfrow = c(1,1))
ts.plot(df$crimes, xlab = "Year-month", ylab = "Number of Armed Robberies", gpars=list(xaxt="n"), main = "Number of Armed Robberies over Time in Boston")
axis(side=1, at=seq(1:118), label=df$month)
```
Fig 1. Monthly number of armed roberies in Boston (Jan 1966 - Oct 1975) 

Variance seems to be unequal. During the initial observations, points are closer together compared with how later in time it tends to spread out.
Data also shows increasing trend over time since the number of maximum and minimum number of armed robberies increases over time.
The presence of seasonality is not very clear from the plot.
In summary, the data is not stationary as it is clear from the plot that both mean and variance are not constant, being instead a function of time.



2. In what way(s) is the data not stationary? The data is not stationary in the ways mentioned before.

Use transformations and/or differencing to make the series stationary. Include a time plot of the transformed and/or differenced data. If you chose a transformation, use this transformation for the remainder steps.


Transforming data using Box Cox transformation and other methods to make the variance constant.
```{r}
lambda <- BoxCox.lambda(df$crimes)
robs_boxcox <- df$crimes^lambda
robs_sqrt = round(sqrt(df$crimes), 2)
robs_log = round(log(df$crimes), 2)
robs_third = (df$crimes)^(1/3)
robs_subs = (df$crimes)^(-1)

df_trans = data.frame(robs_sqrt, robs_log, robs_third, robs_subs, robs_boxcox)

# use tada's code that includes the titles of the plots.
par(mfrow = c(2,3))
for (d in df_trans) {
ts.plot(d, xlab = "Year-month", ylab = "Transformed number of Armed Robberies", gpars=list(xaxt="n"))
axis(side=1, at=seq(1:118), label=df$month)
}
```
Fig 2. Transformations of the monthly number of armed roberies in Boston (Jan 1966 - Oct 1975) 

So we'll stick with the Box-Cox transform to stabilize the variance


```{r}
par(mfrow = c(1,2))
Acf(robs_boxcox); Pacf(robs_boxcox)
```
Figure 3. ACF and PACF of transformed data

The ACF plot shows a trend, no surprise based on the plot of the raw data.
The PACF plot shows an exponential decay, with change of sign, indicating that this, perhaps, is a MA(p) process, although we need to detrend first.



Removing the trend by differencing. Based on the results of ndiffs(), one difference should do.
```{r}
ndiffs(robs_boxcox)

detrend = diff(robs_boxcox, lag = 1, differences = 1)
ndiffs(detrend)


par(mfrow = c(1,1))
ts.plot(detrend, xlab = "Year-month", ylab = " Number of Armed Robberies", gpars=list(xaxt="n"), main = "Detrended Number of Armed Robberies in Boston")
axis(side=1, at=seq(1:118), label=df$month)
```
Figure 4. Detrended Number of Monthly Armed Robberies in Boston

Figure 4 shows the transformed differenced data looks roughly stationary.


Is the data seasonal? Estimating the number of needed seasonal differences
```{r}
nsdiffs(detrend)
```
Gives an error because the data is non seasonal. We don't need to remove seasonality.


3. Using the tranformed and/or differenced data from the previous part, obtain the sample ACF and PACF plots, as well as plots of the raw periodogram, and its smoothed version. Comment on the plots. Use the plots to make a preliminary guess for an appropriate ARIMA model. Keep in mind that differencing plays a part in determining whether the model should be ARMA or ARIMA.


The ACF and PACF plot of the detreneded data look better, we got rid of the trend.Since both ACF and PACF seem to decay exponentially for the differenced series, perhaps this is an ARIMA(p,1,q) process.
The raw and scaled periodograms have their maximum at frequency 0.359

```{r}
P <- 4*abs(fft(detrend)/length(detrend))^2
# |---------- Scaled Periodogram -----------|

Fr <- 0:(length(detrend)-1)/length(detrend)

par(mfrow = c(2,2))
Acf(detrend, lag.max = 30); Pacf(detrend, lag.max = 30)
spec.pgram(detrend); plot(Fr, P, type="o", xlab="frequency", ylab="periodogram")

Fr[which.max(P)]
      # ^ Freq of max periodogram

```
Figure 5. ACF and PACF of transformed and detrended data







RAW PERIODOGRAM AND SMOOTHERED PERIODOGRAM
```{r}
# raw
par(mfrow = c(1,1))
spec.pgram(detrend)

# smoothered (see discussion 9)
spans = c(3, 5, 9, 13, 17, 25, 31)


par(mfrow = c(3,3))
spec.pgram(detrend)
for(k in spans){
spec.pgram(detrend, spans=k, main=paste0('Span ', k))
}
```
Make preliminary guess of appropriate ARIMA / ARMA model would be.




4. Fit the model from the previous step. Include the model, and the parameter estimates. Plot the fitted values and the observed values on the same plot.
```{r}
# how to know what model to fit? Looking at ACF and PACF? See discussion 7
# DO NOT USE AUTO.ARIMA() HERE SINCE HE ASKS FOR IT LATER, AND SPECIFIES ARGUMENTS

fit_1 = Arima(robs_boxcox, order = c(1, 1, 1))
fit_1
```
Parameter estimates:


PLOT FITTED VALUES AND OBSERVED VALUES ON SAME PLOT.
```{r}
plot(df$V2, type = "l")
points(x = 1:117, fit_1$fitted, col = 'darkblue', type = 'l')
# IS NOT WORKING, I DON'T KNOW WHY, FITTED POINTS ARE NOT BEING PLOTTED
```




5. Examine the residuals. Provide necessary plots and/or hypothesis test results. Do the residuals resemble Gaussian white noise?
```{r}
# residuals
res = fit_1$residuals
res
ts.plot(res)

# sample ACF and PACF
par(mfrow = c(2,1))
Acf(res)
Pacf(res)

# Box-Ljung test (H_0: independence of observations in time series)
Box.test(res, lag=10, type="Ljung")

# histogram and normal QQ-plot
par(mfrow = c(2,1))
hist(res)
qqnorm(res)
qqline(res)
```



6. Use AICc to select an ARIMA model for the (possible transformed) data. Keep in mind that differencing should be incorporated into the model. It is fine to use the function auto.arima() here. It is enough to consider p = 0, ..., 8, q = 0, ...,8, and d = 0, 1, 2. Include the chose model, and provide parameter estimates and their standard errors.
```{r}
# with lambda = NULL
fit_2 = auto.arima(robs_boxcox, max.p = 8, max.q = 8, max.P = 2, max.Q = 2, max.d = 2, max.D = 1, ic = "aicc", trace = TRUE)
fit_2
```
The best model is an ARIMA(0,1,2) with drift with AICc = 0.37, where the estimated parameters are:
theta_1: -0.3630 (s.e.: 0.0952)
theta_2: -0.3114 (s.e.: 0.1199)
drift (mu): 0.0245 (s.e.: 0.0072)





7. Inspect the residuals of this model. Provide necessary plots and/or hypothesis test results. Do the residuals resemble Gaussian white noise?
```{r}
# residuals
par(mfrow = c(1,1))
res = fit_2$residuals
res
ts.plot(res, main = "Residuals of the fitted ARIMA(0,1,2) model", ylab = "residuals")

# sample ACF and PACF
par(mfrow = c(1,1))
Acf(res, lag.max = 30)
Pacf(res, lag.max = 30)

# Box-Ljung test (H_0: independence of observations in time series)
Box.test(res, lag=10, type="Ljung")

# histogram and normal QQ-plot
par(mfrow = c(1,1))
hist(res)
qqnorm(res)
qqline(res)
```
The plot of the residuals doesn't show any particular pattern. Also, the ACF and PACF plots show that 95% of the values are inside the 95% CI, indicating that the residuals resemble Gaussian white noise. 
This is supported by the Ljung-Box test, which null hypothesis is that the observations in a time series process are independent. Our residuals, after fitting an ARIMA(0,1,2) model, has a p-value of 0.1512 and therefore, we cannot reject the null with a significance level of 0.05.

Furthermore, the histogram and normal plots show that the residuals of our fitted model have a Gaussian white noise distribution.


Our final best model is ARIMA(0,1,2) since its AICc is lower (0.37) compared with ARIMA(1,1,1)'s AICc (4.45). Therefore, we are going to use this model in the remainding parts of this project.


8. Plot the (theoretical) spectral density of the final model together with the smoothed periodogram. Comment on the plots. Describe the method you chose for smoothing the periodogram.
```{r}

```



9. Now remove the data for 1975 (the last 10 observations). Using only data from 1966 - 1975 (the first 108 observations) fit an ARIMA model using AICc. Again it is fine to use auto.arima(). Then do the following.
```{r}
length(robs_boxcox)

# taking the first 108 observations of the transformed data.
subset_robs = robs_boxcox[1:108]
subset_fsc = robs_boxcox[109:length(robs_boxcox)]

# taking the first 108 observations of the original data.
subs_robs_original = df[1:108, ]
subs_fsc_original = df[109:nrow(df), ]
```


a. Write down the chosen model. Include parameter estimates
```{r}
# for the transformed subset data
fit_3 = auto.arima(subset_robs, max.p = 8, max.q = 8, max.d = 2, ic = "aicc", trace = TRUE)
fit_3


# for the original subset data (before transformation)
#fit_3_original = auto.arima(subs_robs_original[,2], max.p = 8, max.q = 8, max.d = 2, ic = "aicc", trace = TRUE)
#fit_3_original
```
The best model based on the first 108 observations, is an ARIMA(0,1,2) with drift and with AICc = 1.05, where the parameters are:
theta_1: -0.3818 (s.e.: 0.0970)
theta_2: -0.2852 (s.e.: 0.1141)
drift (mu): 0.0265 (s.e.: 0.0077)



b. Inspect the residuals of this model. Do they resemble Gaussian white noise?
```{r}
# residuals
res = fit_3$residuals
res
ts.plot(res, main = "Residuals of the fitted ARIMA(0,1,2) model for the first 108 observations", ylab = "residuals")

# sample ACF and PACF
par(mfrow = c(1,1))
Acf(res, lag.max = 30)
Pacf(res, lag.max = 30)

# Box-Ljung test
Box.test(res, lag=10, type="Ljung") # p-value: 0.5295

# histogram and normal QQ-plot
par(mfrow = c(1,1))
hist(res)
qqnorm(res)
qqline(res)
```
The plot of the residuals doesn't show any particular pattern. Also, the ACF and PACF plots show that all the values at different lags are inside the 95% CI, indicating that the residuals resemble Gaussian white noise.

This is supported by the Ljung-Box test, which null hypothesis is that the observations in a time series process are independent. Our residuals, after fitting an ARIMA(0,1,2) model considering only the first 108 observations, has a p-value of 0.5295 and therefore, we cannot reject the null with a significance level of 0.05.

Furthermore, the histogram and normal plots show that the residuals of our fitted model have a Gaussian white noise distribution.




c. Compute point forecasts of the values for January through October 1975. If you used a transformation, then be sure to compute forecasts of the original data, not the transformed data.
```{r}
fst = forecast(fit_3, h = 10, level = 95)
fst

points_fst = fst$mean^(1/lambda); points_fst
lower = fst$lower^(1/lambda); lower
upper = fst$upper^(1/lambda); upper
```
With the function forecast(), we computed the point forecasts with their respective upper and lower bouds for the 95% CI. After that, the estimated point forecasts and their upper and lower bounds are transformed back the original scale.



d. Make a time plot of the entire data set, the point forecasts, and 95% prediction intervals. Make another plot of just the observed values from 1975 along with the point forecasts and the prediction intervals. Comment on the forecast performance.


Plot of entire data set, point forecasts and 95% prediction intervals
```{r}
n = 108
h = 10

par(mfrow = c(1,1))
ts.plot(df$crimes, ylab = "number of crimes", main = "blala")
polygon(x = c(n+(1:h), n+(h:1)), y = c(upper, lower[h:1]), col = 'lightblue', border = NA)
points(x = n+1:h, y = points_fst, col = 'purple', type = 'b', pch = 19)
points(x = n+1:h, y = subs_fsc_original$crimes, col = 'black', type = 'l')
```


Plot of just the observed values from 1975, point forecasts and prediction intervals.
```{r}
ts.plot(subs_fsc_original$crimes, ylab = "Number of Robberies",main = "Number of Armed Robberies from January 1975 to October 1975 \nin Boston", ylim = c(250, 700))
polygon(x = c(seq(1,10), seq(10,1)), y = c(upper, lower[h:1]), col = 'lightblue', border = NA)
points(seq(1,10), points_fst, col = 'purple', type = 'b', pch = 19)
points(seq(1,10), y = subs_fsc_original$crimes, col = 'black', type = 'l')
```
COMMENT ON THE FORECAST PERFORMANCE:

