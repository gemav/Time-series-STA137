---
title: "Project"
author: "Gema Vidal_7526, Tadaishi Yatabe-Rodriguez_ID_997887941"
date: "March 6, 2017"
output: word_document
---

Loading packages
```{r}
library("astsa")
library("forecast")

```


Setting working directory
```{r, eval = FALSE}
# from Gema's PC
setwd("/Users/gvidal/Box Sync/Vet/MPVM & PhD/PhD 2016_2017 Winter Quarter (gvidal@ucdavis.edu)/STA 137/Project")

# from Gema's Mac
setwd("/Users/gemavidal/Box Sync/Vet/MPVM & PhD/PhD 2016_2017 Winter Quarter (gvidal@ucdavis.edu)/STA 137/Project")

# from Tada's PC
setwd("C:/Users/tyatabe/OneDrive/Docs/PhD Epi/Winter_17/Time series/Project2/Trial")
# From Tada's laptop
setwd("C:/Users/Tadaishi/SkyDrive//Docs/PhD Epi/Winter_17/Time series/Project2/Trial")

df <- read.table("bostonArmedRobberies.txt", header = FALSE)
head(df)
dim(df)
colnames(df) <- c("month", "crimes")
```




1. Use graphical techniques to inspect the data. Describe the behaviour of the data. Mention any features you think may be important for analysis and forecasting.

```{r, eval=T}
ts.plot(df$crimes, xlab = "Year-month", ylab = "Number of Armed Robberies", gpars=list(xaxt="n"))
axis(side=1, at=seq(1:118), label=df$month)
```
Fig 1. Monthly number of armed roberies in Boston (Jan 1966 - Oct 1975) 

Variance seems to be unequal. During the initial observations, points are closer together compared with how later in time it tends to spread out.
Data also shows increasing trend over time since the number of maximum and minimum number of armed robberies increase over time.
The presence of seasonality is not very clear from the plot.
In summary the data is not stationary as it is clear from the plot that both mean and variance are not constant, being instead a function of time.



2. In what way(s) is the data not stationary? The data is not stationary in the ways mentioned before.

Use transformations and/or differencing to make the series stationary. Include a time plot of the transformed and/or differenced data. If you chose a transformation, use this transformation for the remainder steps.


Transforming data using Box Cox transformation and other methods to make the variance constant.
```{r}

lambda <- BoxCox.lambda(df$crimes)
robs_boxcox <- df$crimes^lambda
robs_sqrt = round(sqrt(df$crimes), 2)
robs_log = round(log(df$crimes), 2)
robs_third = (df$crimes)^(1/3)
robs_subs = (df$crimes)^(-1)

df_trans = data.frame(robs_sqrt, robs_log, robs_third, robs_subs, robs_boxcox)

# use tada's code that includes the titles of the plots.Check code discussion 9 for main text
par(mfrow = c(2,3))
for (d in df_trans) {
ts.plot(d, xlab = "Year-month", ylab = "Transformed number of Armed Robberies", gpars=list(xaxt="n"))
axis(side=1, at=seq(1:118), label=df$month)
}

```
Fig 2. Transofmrations of the monthly number of armed roberies in Boston (Jan 1966 - Oct 1975) 

So we'll stick with the Box-Cox transform to stabilize the variance

The ACF plot shows a trend, no surprise based on the plot of the raw data.
The PACF plot shows an exponential decay, with change of sign, indicating that this, perhaps, is a MA(p) process, although we need to detrend first.
```{r}
par(mfrow = c(1,2))
Acf(robs_boxcox); Pacf(robs_boxcox)
```
Figure 3. ACF and PACF of transformed data

Removing the trend by differencing. Based on the results of ndiffs(), one difference should do. Figure 4 shows the transformed differenced data looks roughly stationary.
```{r}
ndiffs(robs_boxcox)

detrend = diff(robs_boxcox, lag = 1, differences = 1)
ndiffs(detrend)

ts.plot(detrend, xlab = "Year-month", ylab = " Number of Armed Robberies", gpars=list(xaxt="n"))
axis(side=1, at=seq(1:118), label=df$month)
```
Figure 4. Detrended Number of Monthly Armed Robberies in Boston


Is the data seasonal? Estimating the number of needed seasonal differences
```{r}
nsdiffs(detrend)
```
Gives an error because the data is non seasonal. We don't need to remove seasonality.


3. Using the tranformed and/or differenced data from the previous part, obtain the sample ACF and PACF plots, as well as plots of the raw periodogram, and its smoothed version. Comment on the plots. Use the plots to make a preliminary guess for an appropriate ARIMA model. Keep in mind that differencing plays a part in determining whether the model should be ARMA or ARIMA.


The ACF and PACF plot of the detreneded data look better, we got rid of the trend. Since both ACF and PACF seem to decay exponentially for the differenced series, with a large ACF and PACF at lag 1, perhaps this is an ARIMA(1,1,1) process.
The raw and smoothed periodograms seem to have their largest values at frequencies just below 4.0. The scaled periodogram have its largest values of 0.014, 0.008, and 0.007 at frequencies 0.359, 0.256, and 0.350, respectively. Of these the most salient is the first one, with a value about twice as much as the one of the next 2. Based on the periodogram, where only one value seems to dominate, the balance seems to incline also for the ARIMA(1,1,1) model(?).

```{r}
P <- 4*abs(fft(detrend)/length(detrend))^2
            #Scaled periodogram^
Fr <- 0:(length(detrend)-1)/length(detrend)

par(mfrow = c(2,2))
Acf(detrend, lag.max = 30); Pacf(detrend, lag.max = 30)
spec.pgram(detrend); spec.pgram(detrend, spans = 5)
# Raw periodogram^    Smoothed periodogram^
plot(Fr, P, type="o", xlab="frequency", ylab="periodogram")
# Scaled periodogram^
Fr[order(P[1:((length(P)-1)/2)], decreasing = T)[1:3]]
      # Freq of 3 largest periodograms^

```
Figure 5. ACF and PACF of detrended data



4. Fit the model form the previous step. Include the model, and the parameter estimates. Plot the fitted values and the observed values on the same plot.

```{r}

fit_1 = Arima(robs_boxcox, order = c(1, 1, 1))
fit_1
```
Parameter estimates: phi = 0.4126; theta = -0.7109. Figure 6 shows the observed and fitted values for this model

```{r}
ts.plot(df$crimes, xlab = "Year-month", ylab = "Number of Armed Robberies", gpars=list(xaxt="n"))
axis(side=1, at=seq(1:118), label=df$month)
points(x = 1:118, fit_1$fitted^(1/lambda), col = 'slateblue', type = 'l')

```
Figure 6. Observed (black line) and fitted (blue line) values for thr ARIMA (1,1,1) model of Boston's monthly armed robberies' frequency



5. Examine the residuals. Provide necessary plots and/or hypothesis test results. Do the residuals resemble Gaussian white noise?

Based on the plot of residuals vs time, the ACF, PACF, Ljung-Box test, and on the histogram and normal Q-Q plot, the residuals look like Gaussian white noise.

```{r}
# residuals
res = fit_1$residuals

# sample ACF and PACF
par(mfrow = c(2,2))
ts.plot(res)
Acf(res, lag=30)
Pacf(res, lag=30)

```
Figure 7. Time plot, ACF, and PACF of residuals

```{r}
# histogram and normal QQ-plot
par(mfrow = c(1,2))
hist(res)
qqnorm(res)
qqline(res)
```
Figure 8. Histogram and normal Q-Q plot of residuals

```{r}
# Box-Ljung test (H_0: independence of observations in time series(stationarity)
Box.test(res, lag=10, type="Ljung")
```


6. Use AICc to select an ARIMA model for the (possible transformed) data. Keep in mind that differencing should be incorporated into the model. It is fine to use the function auto.arima() here. It is enough to consider p = 0, ..., 8, q = 0, ...,8, and d = 0, 1, 2. Include the chose model, and provide parameter estimates and their standard errors.
```{r}
fit_2 = auto.arima(robs_log, max.p = 8, max.q = 8, max.P = 2, max.Q = 2, max.d = 2, max.D = 1)
fit_2
```



7. Inspect the residuals of this model. Provide necessary plots and/or hypothesis test results. Do the residuals resemble Gaussian white noise?
```{r}
# residuals
res = fit_2$residuals
res
ts.plot(res)

# sample ACF and PACF
par(mfrow = c(2,1))
Acf(res)
Pacf(res)

# Box-Ljung test (H_0: independence of observations in time series)
Box.test(res, lag=10, type="Ljung")

# histogram and normal QQ-plot
par(mfrow = c(2,1))
hist(res)
qqnorm(res)
qqline(res)
```



8. Plot the (theoretical) spectral density of the final model together with the smoothed periodogram. Comment on the plots. Describe the method you chose for smoothing the periodogram.

```{r, eval=FALSE}
# Using simulate from forecast package. fit_kk is place-holder for auto.rima ourput
x1 <- simulate(fit_kk, seed=1, future=F)
# Using auto.arima. No place for the drift here (it shouldn't matter though(?))
set.seed(1)
x2 <- arima.sim(n=118, model=list(ma=c(-0.3630, -0.3114), order=c(0,1,2)))

# Differencing simulated data
x2.diff <- diff(x2, lag = 1, differences = 1)
ndiffs(x2.diff)

# Spectral density
P.x <- 4*abs(fft(x2.diff)/length(x2.diff))^2
            #Scaled periodogram^
Fr.x <- 0:(length(x2.diff)-1)/length(x2.diff)
# Plotting
par(mfrow=c(2,2))
spec.pgram(x2.diff); spec.pgram(x2.diff, spans = 5)
# Raw periodogram^    Smoothed periodogram^
plot(Fr.x, P.x, type="o", xlab="frequency", ylab="periodogram")
# Dominating frequencies
Fr.x[order(P.x[1:((length(P.x)-1)/2)], decreasing = T)[1:3]]

```
Figure 11. Raw, smoothed, and scaled periodograms of a simulated ARIMA(0,1,2) time series


9. Now remove the data for 1975 (the last 10 observations). Using only data from 1966 - 1975 (the first 108 observations) fit an ARIMA model using AICc. Again it is fine to use auto.arima(). Then do the following.
```{r}
dim(df)

# taking the first 158 observations.
subset_robs = df[1:108, ]
subset_fsc = df[109:nrow(df), ]
```


a. Write down the chosen model. Include parameter estimates
```{r}
fit_3 = auto.arima()

```


b. Inspect the residuals of this model. Do they resemble Gaussian white noise?
```{r}
# residuals
res = fit_3$residuals
res
ts.plot(res)

# sample ACF and PACF
par(mfrow = c(2,1))
Acf(res)
Pacf(res)

# Box-Ljung test
Box.test(res, lag=10, type="Ljung") # p-value: 0.5725

# histogram and normal QQ-plot
par(mfrow = c(2,1))
hist(res)
qqnorm(res)
qqline(res)
```


c. Compute point forecasts of the values for January through October 1975. If you used a transformation, then be sure to compute forecasts of the original data, not the transmformed data.
```{r}
fst = predict(fit_3, n.ahead = 10)
fst$pred
```


d.Make a time plot of the entire data set, the point forecasts, and 95% prediction intervals. Make another plot of just the observed values from 1975 along with the point forecasts and the prediction intervals. Commnent on the forecast performance.
```{r}
# CONFIRM THIS CODE
n = 158
h = 5

par(mfrow = c(1,1))
ts.plot(temp[,2])
polygon(x = c(n+(1:h), n+(h:1)), y = c(upper, lower[h:1]), col = 'lightblue', border = NA)
points(x = n+1:h, y = fst$pred, col = 'purple', type = 'b', pch = 19)

# zoom in
ts.plot(subset_fsc[,2], ylim = c(0.30, 0.48))
points(seq(1,5), fst$pred, col = 'purple', type = 'b', pch = 19)

upper = fst$pred + fst$se
lower = fst$pred - fst$se

polygon(x = c(seq(1,5), seq(5,1)), y = c(upper, lower[h:1]), col = 'lightblue', border = NA)
```

